{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "585c823e-6fe1-4fe8-adc5-0d51890db1e7",
   "metadata": {},
   "source": [
    "# Demo 3: Accelerating ML inference via distributed processing and/or Triton inference servers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c56e44d-019a-4583-9ba8-691686cd851c",
   "metadata": {
    "tags": []
   },
   "source": [
    "In this demo we show how analysis workflows can be accelerated by parallelizing processing, or by outsourcing the ML inference to Triton servers with GPUs.\n",
    "\n",
    "First, let's load the pre-selected dimuon events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b7568c-e128-49e8-99f5-d50973e657b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from python.event_selection import load_events\n",
    "from python.dnn_model import NeuralNet\n",
    "\n",
    "sources = [\"data\", \"ttbar\", \"dy\"]\n",
    "server = \"file:/depot/cms/purdue-af/demos/\"\n",
    "model_dir = \"/depot/cms/purdue-af/demos/\"\n",
    "dfs = {}\n",
    "\n",
    "features = ['mu1_pt', 'mu1_eta', 'mu2_pt', 'mu2_eta', 'dimuon_mass', 'met']\n",
    "\n",
    "# load datasets for inference\n",
    "for src in sources:\n",
    "    dfs[src] = load_events(f\"{server}/{src}.root\")[features]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7783af21-2821-4576-9967-eaa9fdfe893d",
   "metadata": {},
   "source": [
    "## 1. Distributed processing with Dask\n",
    "The `dask.distributed` package provides a quick way to process embarassingly parallel workflows using multiple local or remote computing nodes. This is done by spawning a *cluster* of workers (for remote workers - using a batch submission system like SLURM), and then creating a *client* to interact with that cluster.\n",
    "\n",
    "Here we demonstrate two ways to use Dask clusters - create a local cluster within a notebook, or connect to a cluster created elsewhere. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b7b365-e1c6-47aa-af94-9d6ddd5d4e94",
   "metadata": {},
   "source": [
    "### Create a local cluster\n",
    "The local cluster can be scaled up to the number of CPUs selected at session start (up to 32). In this case, all Dask workers will be running on the same node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0bda4f-3cb7-443d-b0ce-d3170446c80a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dask.distributed import LocalCluster, Client\n",
    "cluster = LocalCluster(n_workers=4)\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235a5355-407e-4c57-a843-ba0a86be8624",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Connect to an existing cluster\n",
    "In this case, the cluster is launched elsewhere (e.g. in a different notebook, terminal, or through Dask JupyterLab extension), and only its address is needed to create the client.\n",
    "\n",
    "Work is currently in progress to develop reliable cluster setups that will allow to use more than 32 CPUs and utilize more than one computing node at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92da10ce-0a7c-4d49-bd41-f3a4f003a685",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from dask.distributed import Client\n",
    "\n",
    "# client = Client(\"tcp://127.0.0.1:42573\")\n",
    "# client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a29e3fe-048d-4f8a-91ae-698bbb903d36",
   "metadata": {},
   "source": [
    "### Example parallelization\n",
    "In order to test the distributed processing setup, we run a simple DNN inference for three small datasets in parallel. Here DNN inference is just an example of a processing code that can be parallelized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8c9940-6894-44ba-a4b3-387cbc1458ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check if there are any local GPUs available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Will use GPU for inference.\")\n",
    "else:\n",
    "    print(\"Will use CPUs for inference.\")\n",
    "\n",
    "# The main processing function that will be executed in parallel on multiple datasets\n",
    "def inference(inp):\n",
    "    label = inp[0]\n",
    "    df = inp[1]\n",
    "    model_path=model_dir+\"/model.ckpt\"\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    model = NeuralNet(6, [16, 8], 1).to(device)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "    df = torch.from_numpy(df.values).to(device).float()\n",
    "    scores = model(df) \n",
    "    scores = scores.cpu().detach().numpy()\n",
    "    return {\n",
    "        \"label\": label,\n",
    "        \"output\": scores.ravel()\n",
    "    }\n",
    "\n",
    "# Distribute the datasets to workers\n",
    "scattered_data = client.scatter(list(dfs.items()))\n",
    "\n",
    "# Process the datasets in parallel and return the results\n",
    "futures = client.map(inference, scattered_data)\n",
    "results = client.gather(futures)\n",
    "\n",
    "print(\"\\nInference outputs:\")\n",
    "for res in results:\n",
    "    print(res[\"label\"], res[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73d0873-9644-47cd-aa4e-76bf619f8dfe",
   "metadata": {},
   "source": [
    "## 2. Outsourcing ML inference to remote GPUs via Triton servers\n",
    "Machine learning inference is known to run much faster on GPUs as compared to CPUs. However, computing clusters are usually limited in number of GPUs, therefore it is not possible to ensure full access to GPUs for all users at all times.\n",
    "\n",
    "An approach allowing to use the power of GPUs to accelerate inference without blocking the GPU nodes is to use dedicated inference servers which are always connected to GPUs.\n",
    "\n",
    "In order to be able to evaluate a model via a Triton server, the model has to be saved in a special way: [see example how to do that in PyTorch](https://medium.com/@furcifer/deploying-triton-inference-server-in-5-minutes-67aa09a84ca6).\n",
    "\n",
    "The saved models must be put into a repository visible to the Triton server(s), which in our case is `/depot/cms/purdue-af/triton/models/`.\n",
    "\n",
    "At the moment, we provide several Triton servers corresponding to different GPUs / GPU partitions. To select a particular server, simply uncomment the corresponding address:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad5c7cb-636f-4b96-a833-2b84ed7f1c19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "triton_address = '128.211.160.154:8001' # Partition of A100 GPU with 5gb RAM\n",
    "#triton_address = '128.211.160.153:8001' # Partition of A100 GPU with 10gb RAM\n",
    "#triton_address = '128.211.160.147:8001' # Partition of A100 GPU with 20gb RAM\n",
    "#triton_address = 'hammer-f000.rcac.purdue.edu:8001' # T4 GPU located at a different cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327803d1-3aac-47fa-b273-8245b2df80b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tritonclient.grpc as grpcclient\n",
    "\n",
    "print(f\"Connecting to Triton inference sever at {triton_address}\")\n",
    "\n",
    "keepalive_options = grpcclient.KeepAliveOptions(\n",
    "    keepalive_time_ms=2**31 - 1,\n",
    "    keepalive_timeout_ms=20000,\n",
    "    keepalive_permit_without_calls=False,\n",
    "    http2_max_pings_without_data=2\n",
    ")\n",
    "\n",
    "def inference_triton(inp):\n",
    "    # Create Triton client\n",
    "    try:\n",
    "        triton_client = grpcclient.InferenceServerClient(\n",
    "            url=triton_address,\n",
    "            verbose=False,\n",
    "            keepalive_options=keepalive_options\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(\"Channel creation failed: \" + str(e))\n",
    "        sys.exit()\n",
    "    \n",
    "    label= inp[0]\n",
    "    df = inp[1]\n",
    "    \n",
    "    # Inputs and outputs should be compatible with model metadata\n",
    "    # stored in /depot/cms/purdue-af/triton/models/test-model/config.pbtxt\n",
    "    inputs = [grpcclient.InferInput('INPUT__0', df.shape, \"FP64\")]\n",
    "    outputs = [grpcclient.InferRequestedOutput('OUTPUT__0')]\n",
    "    \n",
    "    # Load input data\n",
    "    inputs[0].set_data_from_numpy(df.values)\n",
    "    \n",
    "    # Run inference on Triton server.\n",
    "    # Models are stored in /depot/cms/purdue-af/triton/models/\n",
    "    results = triton_client.infer(\n",
    "        model_name=\"test-model\",\n",
    "        inputs=inputs,\n",
    "        outputs=outputs,\n",
    "        headers={'test': '1'},\n",
    "    )\n",
    "\n",
    "    output = results.as_numpy('OUTPUT__0')\n",
    "    return {\n",
    "        \"label\": label,\n",
    "        \"output\": output.flatten()\n",
    "    }\n",
    "\n",
    "results = []\n",
    "for label, df in dfs.items():\n",
    "    results.append(inference_triton([label, df]))\n",
    "\n",
    "\n",
    "print(\"\\nInference outputs:\")\n",
    "for res in results:\n",
    "    print(res[\"label\"], res[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80b9b45-63b9-4f02-8c87-31629416c8ec",
   "metadata": {},
   "source": [
    "DNN inference via Triton servers can also be parallelized using Dask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9713f8-e2d6-4f79-ad15-82dae070b9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scattered_data = client.scatter(list(dfs.items()))\n",
    "# futures = client.map(inference_triton, scattered_data)\n",
    "# results = client.gather(futures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a10a999-1f08-4928-8a7a-99d8091af1b4",
   "metadata": {},
   "source": [
    "## Plotting DNN outputs\n",
    "Run this cell after either Dask parallelization example or after Triton example to plot the DNN outputs (note that the models are different in these examples, so the outputs will not look the same). The models are generic and not meant to provide any physics meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747f337c-d48c-438f-b78b-a3837c3d5d3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "bins = np.linspace(0, 1, 100)\n",
    "plt.figure(figsize=(5,4))\n",
    "\n",
    "dnn = {res[\"label\"]: res[\"output\"] for res in results}\n",
    "\n",
    "plt.hist(dnn[\"dy\"], bins, alpha=0.3, label='dy', density=True)\n",
    "plt.hist(dnn[\"ttbar\"], bins, alpha=0.3, label='ttbar', density=True)\n",
    "plt.hist(dnn[\"data\"], bins, alpha=0.3, label='data', density=True)\n",
    "plt.xlabel('DNN Score')\n",
    "plt.ylabel('Events')\n",
    "leg = plt.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64f4b2e-3cfe-4f72-ad99-40b52308d4f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 kernel [ML]",
   "language": "python",
   "name": "python3-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
